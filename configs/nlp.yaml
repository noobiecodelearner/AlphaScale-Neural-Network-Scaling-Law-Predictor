domain: nlp
dataset: yahoo
data_path: data/raw/yahoo
num_classes: 10
vocab_size: 30522
max_seq_len: 128

dataset_fractions:
  - 0.25
  - 0.5
  - 1.0

model_scales:
  layer_dim_pairs:
    - [1, 16]
    - [1, 48]
    - [1, 64]
    - [2, 128]
    - [4, 256]

training:
  epochs: 15
  batch_size: 128
  optimizer: adamw
  learning_rate: 0.0001
  weight_decay: 0.00001

energy:
  gpu_wattage: 250
